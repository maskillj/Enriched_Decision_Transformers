{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaskillj\u001b[0m (\u001b[33mmaskillj-university-of-leeds\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "/Users/jamesmaskill/miniforge3/envs/py10env/lib/python3.10/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./log/dt/d4rl_corl/walker2d-medium-replay-v2_seed42-09-06-22-41-50019/wandb/run-20240906_224144-2z0er46y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/maskillj-university-of-leeds/uncategorized/runs/2z0er46y' target=\"_blank\">walker2d-medium-replay-v2_seed42-09-06-22-41-50019</a></strong> to <a href='https://wandb.ai/maskillj-university-of-leeds/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/maskillj-university-of-leeds/uncategorized' target=\"_blank\">https://wandb.ai/maskillj-university-of-leeds/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/maskillj-university-of-leeds/uncategorized/runs/2z0er46y' target=\"_blank\">https://wandb.ai/maskillj-university-of-leeds/uncategorized/runs/2z0er46y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesmaskill/miniforge3/envs/py10env/lib/python3.10/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "load datafile: 100%|██████████| 11/11 [00:01<00:00,  6.51it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 73\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mstep_per_epoch):\n\u001b[1;32m     72\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(trainloader_iter)\n\u001b[0;32m---> 73\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i_epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     76\u001b[0m     eval_metrics \u001b[38;5;241m=\u001b[39m eval_decision_transformer(env, policy, [\u001b[38;5;241m300\u001b[39m], args\u001b[38;5;241m.\u001b[39mreturn_scale, args\u001b[38;5;241m.\u001b[39meval_episode, seed\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mseed, max_drawdowns\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Decision_Transformers/VS_Implementation/src/drawdown_control/decision_transformer_policy.py:93\u001b[0m, in \u001b[0;36mDecisionTransformerPolicy.update\u001b[0;34m(self, batch, clip_grad)\u001b[0m\n\u001b[1;32m     91\u001b[0m actor_loss \u001b[38;5;241m=\u001b[39m (actor_loss \u001b[38;5;241m*\u001b[39m masks\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt_optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 93\u001b[0m \u001b[43mactor_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clip_grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mparameters(), clip_grad)\n",
      "File \u001b[0;32m~/miniforge3/envs/py10env/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py10env/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py10env/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/Users/jamesmaskill/Desktop/Decision_Transformers/VS_Implementation/src')\n",
    "\n",
    "from drawdown_control.decision_transformer import *\n",
    "from drawdown_control.decision_transformer_policy import *\n",
    "from drawdown_control.trajectory_processing import *\n",
    "from drawdown_control.evaluate import *\n",
    "\n",
    "import wandb\n",
    "from UtilsRL.logger import CompositeLogger\n",
    "from torch.utils.data import DataLoader\n",
    "from UtilsRL.exp import parse_args, setup\n",
    "import d4rl\n",
    "\n",
    "args = parse_args(\"/Users/jamesmaskill/Desktop/Decision_Transformers/VS_Implementation/config/walker/walker_medium_replay_v2.py\")\n",
    "exp_name = \"_\".join([args.task, \"seed\"+str(args.seed)]) \n",
    "logger = CompositeLogger(log_dir=f\"./log/dt/{args.name}\", name=exp_name, logger_config={\n",
    "    \"TensorboardLogger\": {}, \n",
    "    \"WandbLogger\": {\"config\": args, \"settings\": wandb.Settings(_disable_stats=True), **args.wandb}\n",
    "})\n",
    "setup(args, logger)\n",
    "env, dataset = get_d4rl_dataset(args.task, normalize_obs=args.normalize_obs, normalize_reward=args.normalize_reward, discard_last=False)\n",
    "obs_shape = env.observation_space.shape[0]\n",
    "action_shape = env.action_space.shape[-1]\n",
    "\n",
    "offline_buffer = D4RLTrajectoryBuffer(dataset, seq_len=args.seq_len, return_scale=args.return_scale)\n",
    "indices = [i for i, x in enumerate(dataset['terminals']) if x]\n",
    "episode_lengths = [indices[0]] + [indices[i] - indices[i-1] for i in range(1, len(indices))]\n",
    "max_len = 2048\n",
    "\n",
    "dt = DecisionTransformer(\n",
    "    obs_dim=obs_shape, \n",
    "    action_dim=action_shape, \n",
    "    embed_dim=args.embed_dim, \n",
    "    num_layers=args.num_layers, \n",
    "    seq_len= args.seq_len+args.episode_len \\\n",
    "        if args.use_abs_timestep else args.seq_len, \n",
    "    num_heads=args.num_heads, \n",
    "    attention_dropout=args.attention_dropout, \n",
    "    residual_dropout=args.residual_dropout, \n",
    "    embed_dropout=args.embed_dropout, \n",
    "    pos_encoding=args.pos_encoding,\n",
    "    max_seq_len = max_len\n",
    ").to('cpu')\n",
    "\n",
    "policy = DecisionTransformerPolicy(\n",
    "    dt=dt, \n",
    "    state_dim=obs_shape,\n",
    "    action_dim=action_shape, \n",
    "    embed_dim=args.embed_dim, \n",
    "    seq_len=args.seq_len, \n",
    "    episode_len=args.episode_len, \n",
    "    use_abs_timestep=args.use_abs_timestep, \n",
    "    policy_type=args.policy_type, \n",
    "    device='cpu'\n",
    ").to('cpu')\n",
    "policy.configure_optimizers(lr=args.lr, weight_decay=args.weight_decay, betas=args.betas, warmup_steps=args.warmup_steps)\n",
    "\n",
    "# main loop   \n",
    "policy.train()\n",
    "trainloader = DataLoader(\n",
    "    offline_buffer, \n",
    "    batch_size=args.batch_size, \n",
    "    pin_memory=True,\n",
    "    num_workers=args.num_workers\n",
    ")\n",
    "trainloader_iter = iter(trainloader)\n",
    "for i_epoch in range(1, args.max_epoch+1):\n",
    "    for i_step in range(args.step_per_epoch):\n",
    "        batch = next(trainloader_iter)\n",
    "        train_metrics = policy.update(batch, clip_grad=args.clip_grad)\n",
    "    \n",
    "    if i_epoch % 2 == 0:\n",
    "        eval_metrics = eval_decision_transformer(env, policy, [300], args.return_scale, args.eval_episode, seed=args.seed, max_drawdowns=-20)\n",
    "        logger.info(f\"Episode {i_epoch}: \\n{eval_metrics}\")\n",
    "    \n",
    "    if i_epoch % args.log_interval == 0:\n",
    "        logger.log_scalars(\"\", train_metrics, step=i_epoch)\n",
    "        logger.log_scalars(\"Eval\", eval_metrics, step=i_epoch)\n",
    "        \n",
    "    if i_epoch % args.save_interval == 0:\n",
    "        logger.log_object(name=f\"policy_{i_epoch}.pt\", object=policy.state_dict(), path=f\"./out/dt/d4rl/{args.name}/{args.task}/seed{args.seed}/policy/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
